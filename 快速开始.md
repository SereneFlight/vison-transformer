# 🚀 快速开始

> 如果你不知道从哪里开始，看这个文件！

---

## 📖 5 分钟快速入门

### 1️⃣ 运行测试（确认代码能跑）

```bash
cd ~/桌面/vla_learning/vit_from_scratch
python3 test_model.py
```

**你会看到**:
- ✅ 7 个测试全部通过
- 看到每一层的输出形状变化
- 参数量: ~86M

---

### 2️⃣ 理解整体架构（10 分钟）

**打开**: `README.md`

**重点看**:
- 第二节: 整体架构流程图（画在纸上！）
- 第三节: 核心模块说明
- 第四节: 关键参数对照表

**记住这 5 个关键数字**:
```
224  - 图像大小
16   - Patch 大小
196  - Patch 数量 (14×14)
768  - 嵌入维度
12   - Transformer 层数
```

---

### 3️⃣ 理解 Attention（30 分钟 - 最重要！）

**打开**: `vit_architecture.md`

**只看第 3 节**: Multi-Head Attention 详解

**重点**:
- 3.1: Self-Attention 原理（Q、K、V 的含义）
- 3.2: 公式推导（为什么除以 √d）
- 3.3: Multi-Head 的意义
- 3.4: 详细维度变化（**一定要看懂这个**）

---

### 4️⃣ 阅读代码（1 小时）

**打开**: `vit_model.py`

**阅读顺序**:
1. `PatchEmbed` (第 25 行) - 最简单
2. `MLP` (第 145 行) - 第二简单
3. `Attention` (第 60 行) - 最难，慢慢看
4. `Block` (第 195 行) - 组合上面两个
5. `VisionTransformer` (第 245 行) - 串联所有模块

**不要着急手写！先看懂！**

---

## 📚 完整学习路线

### 今天（2-3 小时）
- [x] 运行测试
- [ ] 看懂 README.md
- [ ] 理解 Attention 机制
- [ ] 通读代码（不要求全懂）

### 明天或后天（4-6 小时）
- [ ] 手写 PatchEmbed
- [ ] 手写 MLP
- [ ] 手写 Attention（难点）
- [ ] 手写 Block
- [ ] 手写 VisionTransformer

### 第三天（2-3 小时）
- [ ] 可视化 Attention Map
- [ ] 在 CIFAR-10 上训练
- [ ] 记录到 Notion

---

## 🎯 学习目标检查

看完今天的内容后，你应该能回答这些问题：

### 基础问题
1. ViT 把图像看作什么？
   <details>
   <summary>点击查看答案</summary>
   序列（Sequence）。把图像切成 patches，每个 patch 是一个 token。
   </details>

2. 224×224 的图像会切成多少个 patches？
   <details>
   <summary>点击查看答案</summary>
   196 个 (14×14)。因为 224/16 = 14。
   </details>

3. CLS token 的作用是什么？
   <details>
   <summary>点击查看答案</summary>
   聚合全局信息用于分类。借鉴 BERT 的设计。
   </details>

### Attention 问题
4. Q、K、V 分别代表什么？
   <details>
   <summary>点击查看答案</summary>
   - Q (Query): 我要查询什么信息
   - K (Key): 我有什么信息
   - V (Value): 我的信息内容
   </details>

5. 为什么要除以 √d？
   <details>
   <summary>点击查看答案</summary>
   防止点积过大导致 softmax 梯度消失。d=64 时，√d ≈ 8。
   </details>

6. 为什么要用多头？
   <details>
   <summary>点击查看答案</summary>
   每个头可以学习不同的模式（边缘、纹理、颜色等），类似 CNN 的多通道。
   </details>

### 架构问题
7. ViT-Base 有多少参数？
   <details>
   <summary>点击查看答案</summary>
   ~86M（85,806,346 个）
   </details>

8. 为什么 ViT 在小数据集上不如 CNN？
   <details>
   <summary>点击查看答案</summary>
   CNN 有强归纳偏置（局部性、平移不变性），ViT 几乎没有，需要大规模数据学习。
   </details>

---

## 🔧 常见问题

### Q: 我代码能力很差，能学会吗？
**A**: 当然可以！我已经写了超详细的注释，你先理解再手写。**代码能力是练出来的**。

### Q: Attention 太难了，看不懂怎么办？
**A**: 正常！Attention 是最难的部分。建议：
1. 先看 `vit_architecture.md` 第 3.4 节的维度变化
2. 用纸笔画出 (2,197,768) → (2,12,197,64) 的过程
3. 创建小 tensor 实验：
   ```python
   import torch
   x = torch.randn(2, 197, 768)
   x = x.reshape(2, 197, 3, 12, 64)
   print(x.shape)
   ```

### Q: 需要 GPU 吗？
**A**: 不需要！测试代码用 CPU 就能跑。真正训练时可以用 GPU，但不是必须的。

### Q: 我应该手写多少遍？
**A**: 建议：
- 第 1 遍：对着我的代码敲，理解每一行
- 第 2 遍：看着注释自己写
- 第 3 遍：完全自己写（可以查文档）

### Q: 遇到 bug 怎么办？
**A**:
1. 打印每一步的 shape：`print(f"x: {x.shape}")`
2. 对照我的代码检查
3. 用小数据测试：`x = torch.randn(1, 3, 224, 224)`

---

## 📂 文件导航

```
vit_from_scratch/
├── 快速开始.md           ← 你在这里！从这开始
├── 学习指南.md            ← 详细学习路线
├── README.md              ← 整体架构（必看）
├── vit_architecture.md    ← 数学原理（重点看第 3 节）
├── vit_model.py           ← 完整代码（500+ 行注释）
└── test_model.py          ← 测试代码（理解维度变化）
```

**建议阅读顺序**:
1. **快速开始.md** (本文件) - 5 分钟
2. **README.md** - 10 分钟
3. **vit_architecture.md** 第 3 节 - 30 分钟
4. **vit_model.py** - 1 小时
5. **学习指南.md** - 看下一步计划

---

## 💡 学习技巧

### 1. 画图！
用纸笔画出：
- 整体流程图
- Attention 的维度变化
- 多头的拆分和合并

### 2. 实验！
```python
# 不懂就试试
x = torch.randn(2, 3, 4)
print(x.shape)

x2 = x.reshape(2, 3, 2, 2)
print(x2.shape)

x3 = x.transpose(1, 2)
print(x3.shape)
```

### 3. 对比！
| 操作 | CNN | ViT |
|------|-----|-----|
| 输入 | 图像 | Patches (tokens) |
| 感受野 | 局部→全局 | 第一层就全局 |
| 关键操作 | 卷积 | Self-Attention |

---

## ✅ 今天的小目标

**只需要做到这 3 点**:
1. [ ] 运行测试，看到所有测试通过 ✅
2. [ ] 看懂整体架构流程图（能画在纸上）
3. [ ] 理解 Q、K、V 的含义

**明天继续！不着急！** 😊

---

## 🆘 需要帮助？

**遇到任何问题都可以问我！**

我会非常详细地解答，因为：
1. 你的理解能力很好（翻译论文、提问都很到位）
2. 代码能力是可以快速提升的
3. 我希望你能完全掌握 ViT，为你的科研打基础

**加油！🚀**
